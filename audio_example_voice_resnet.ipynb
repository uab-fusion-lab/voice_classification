{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T14:23:14.057097900Z",
     "start_time": "2024-07-31T14:23:05.490176900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'never'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_excel('./data/data/NEW_IRB300012145_Patient_ID_deidentified.xlsx')\n",
    "Smokeing_status = labels_df.iloc[:, 4].to_list()\n",
    "\n",
    "Smokeing_status[149]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T14:24:59.554726700Z",
     "start_time": "2024-07-31T14:24:58.868666700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import torchaudio.transforms as T\n",
    "\n",
    "class AmplitudeNormalization:\n",
    "    def __call__(self, waveform):\n",
    "        # Normalize the waveform to be within [-1, 1]\n",
    "        peak = waveform.abs().max()\n",
    "        if peak > 0:\n",
    "            waveform = waveform / peak\n",
    "        return waveform\n",
    "\n",
    "# To use it:\n",
    "# waveform, sample_rate = torchaudio.load('path/to/audio.wav')\n",
    "# waveform = AmplitudeNormalization()(waveform)\n",
    "\n",
    "\n",
    "class PadTrimAudio:\n",
    "    def __init__(self, max_len):\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, waveform):\n",
    "        if waveform.size(1) > self.max_len:\n",
    "            # Trim the waveform if longer than max_len\n",
    "            waveform = waveform[:, :self.max_len]\n",
    "        elif waveform.size(1) < self.max_len:\n",
    "            # Pad with zeros if shorter than max_len\n",
    "            padding_size = self.max_len - waveform.size(1)\n",
    "            waveform = torch.nn.functional.pad(waveform, (0, padding_size), \"constant\", 0)\n",
    "\n",
    "        if waveform.size(0) < 128:\n",
    "            padding_size = 128 - waveform.size(0)\n",
    "            waveform = torch.nn.functional.pad(waveform, (padding_size, 0), \"constant\", 0)\n",
    "        return waveform\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "class FeatureNormalization:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "\n",
    "    def fit(self, features):\n",
    "        # Fit the scaler on the training set features\n",
    "        self.scaler.fit(features)\n",
    "\n",
    "    def transform(self, features):\n",
    "        # Apply normalization to features\n",
    "        return self.scaler.transform(features)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T14:25:03.896744700Z",
     "start_time": "2024-07-31T14:25:01.143009300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_int = {\n",
    "    'N': 0,\n",
    "    'Y': 1\n",
    "}\n",
    "\n",
    "label_to_int['N']"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T14:32:19.101155400Z",
     "start_time": "2024-07-31T14:32:19.089577700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "label_to_int = {\n",
    "    'F': 0,\n",
    "    'M': 1\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "label_to_int = {\n",
    "    'current': 0,\n",
    "    'former': 0,\n",
    "    'never': 1\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class SoundDataset(Dataset):\n",
    "    def __init__(self, data_dir, labels_df, transform=None, max_len=10000):\n",
    "        self.data_dir = data_dir\n",
    "        self.labels_df = labels_df\n",
    "        self.transform = transform\n",
    "        self.max_len = max_len\n",
    "        # self.orderlist = ['RLP.wav', 'RUP.wav', 'RUA Hum.wav', 'LUA Hum.wav', 'RUA.wav', 'RMP.wav', 'LMP.wav', 'LUA.wav', 'LLP.wav', 'LUP.wav']\n",
    "        self.orderlist = ['a.wav', 'a_high.wav', 'a_low.wav', 'consent.wav', 'cough_n.wav', 'e.wav', 'e_high.wav', 'e_low.wav', 'pain_rating.wav', 'SOB_rating.wav', 'two_roads.wav']\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels_df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        patient_id = str(idx+1).zfill(3)\n",
    "        # audio_dir = os.path.join(self.data_dir, str(patient_id), 'breath Eko')\n",
    "        audio_dir = os.path.join(self.data_dir, str(patient_id), 'Voice')\n",
    "        audio_file = [os.path.join(audio_dir, f) for f in os.listdir(audio_dir) if f.endswith('.wav') and '_' not in f][0]\n",
    "\n",
    "\n",
    "        y, sr = librosa.load(audio_file, sr=None)\n",
    "\n",
    "\n",
    "        D = librosa.stft(y, n_fft=2048, hop_length=512)  # n_fft and hop_length can be adjusted based on your needs\n",
    "        S = np.abs(D) ** 2  # Convert to power spectrum\n",
    "        mel_spec = librosa.feature.melspectrogram(S=S, sr=sr, n_mels=128)\n",
    "\n",
    "            # print(mel_spec)\n",
    "            # plt.figure(figsize=(10, 4))\n",
    "            # librosa.display.specshow(librosa.power_to_db(mel_spec, ref=np.max), sr=sr, hop_length=512, x_axis='time', y_axis='mel')\n",
    "            # plt.colorbar(format='%+2.0f dB')\n",
    "            # plt.title('Mel spectrogram')\n",
    "            # plt.tight_layout()\n",
    "            # plt.show()\n",
    "            # print(len(y))\n",
    "            # print(sr)\n",
    "\n",
    "            # if self.transform:\n",
    "            #     waveform = self.transform(waveform)\n",
    "        waveform = PadTrimAudio(self.max_len)(torch.tensor(mel_spec))\n",
    "\n",
    "\n",
    "        label = label_to_int[self.labels_df[idx]]\n",
    "\n",
    "        return waveform, label\n",
    "\n",
    "transform = AmplitudeNormalization()\n",
    "data_dir = './data/data/Patients'\n",
    "sound_dataset = SoundDataset(data_dir, Smokeing_status, transform=transform)\n",
    "\n",
    "train_dataset, test_dataset = random_split(sound_dataset, [180, 20])\n",
    "\n",
    "traindataloader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "testdataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)\n",
    "\n",
    "dataloader = DataLoader(sound_dataset, batch_size=20, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T14:32:20.334561400Z",
     "start_time": "2024-07-31T14:32:20.325243100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 0, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 0, 0, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 0, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 0, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 0, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 0, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 0, 0, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 0, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 0, 0, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 0, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 0, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 0, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 0, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 0, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 0, 0, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 0, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 0, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 0, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 0, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 0, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 0, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 0, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 0, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 0, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 0, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 0, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 0, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for batch in traindataloader:\n",
    "    waveforms, labels = batch\n",
    "    print(waveforms.shape)\n",
    "    print(labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 0, 1, 1])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([0, 1, 0, 0])\n",
      "torch.Size([4, 128, 10000])\n",
      "tensor([1, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch in testdataloader:\n",
    "    waveforms, labels = batch\n",
    "    print(waveforms.shape)\n",
    "    print(labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T14:32:46.486415500Z",
     "start_time": "2024-07-31T14:32:44.989845200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "def conv1d3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv1d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv1d3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm1d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv1d3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm1d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=False):\n",
    "        super(ResNet1D, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Conv1d(128, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                conv1d3x3(self.inplanes, planes * block.expansion, stride),\n",
    "                nn.BatchNorm1d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "def AudioClassifier(**kwargs):\n",
    "    return ResNet1D(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "\n",
    "# class AudioClassifier(nn.Module):\n",
    "#     def __init__(self, num_classes=2):\n",
    "#         super(AudioClassifier, self).__init__()\n",
    "#         resnet = resnet18(pretrained=True)  # Load a pretrained ResNet18 model\n",
    "#\n",
    "#         # Modify the first convolutional layer to accept 1D input\n",
    "#         self.resnet = nn.Sequential(\n",
    "#             nn.Conv1d(128, 64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "#             resnet.bn1,\n",
    "#             resnet.relu,\n",
    "#             resnet.maxpool,\n",
    "#             resnet.layer1,\n",
    "#             resnet.layer2,\n",
    "#             resnet.layer3,\n",
    "#             resnet.layer4,\n",
    "#             nn.AdaptiveAvgPool1d(1)  # Adapting pool for 1D\n",
    "#         )\n",
    "#\n",
    "#         # Replace the fully connected layer\n",
    "#         self.fc = nn.Linear(512, num_classes)\n",
    "#\n",
    "#     def forward(self, x):\n",
    "#         x = self.resnet(x)\n",
    "#         x = torch.flatten(x, 1)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n",
    "\n",
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        # Flatten the input from 1280x1000 to 1280000\n",
    "        self.fc1 = nn.Linear(1280 * 1000, 1024)  # First fully connected layer\n",
    "        self.fc2 = nn.Linear(1024, 512)          # Second fully connected layer\n",
    "        self.fc3 = nn.Linear(512, 3)             # Output layer for 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Flatten the input\n",
    "        x = x.view(-1, 1280 * 1000)  # Ensure input tensor is reshaped to (batch_size, 1280*1000)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # No activation function here as it will be used with CrossEntropyLoss\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T14:35:42.434587900Z",
     "start_time": "2024-07-31T14:35:42.429998100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def test_model(model, test_loader, device='cpu'):\n",
    "    \"\"\"\n",
    "    Tests the given model on the provided test data loader.\n",
    "\n",
    "    Parameters:\n",
    "        model (torch.nn.Module): The model to test.\n",
    "        test_loader (torch.utils.data.DataLoader): DataLoader for the test set.\n",
    "        device (str): Device to run the model on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        float: Accuracy of the model on the test set.\n",
    "    \"\"\"\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            print(labels)\n",
    "            print(predicted)\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Accuracy of the model on the test set: {accuracy:.2f}%')\n",
    "\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T14:35:43.742251500Z",
     "start_time": "2024-07-31T14:35:43.734089800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.3844, Accuracy: 50.56%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "Accuracy of the model on the test set: 25.00%\n",
      "Epoch 2, Loss: 0.8599, Accuracy: 53.33%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "Accuracy of the model on the test set: 70.00%\n",
      "Epoch 3, Loss: 0.7986, Accuracy: 52.22%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "Accuracy of the model on the test set: 70.00%\n",
      "Epoch 4, Loss: 0.7138, Accuracy: 57.22%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "Accuracy of the model on the test set: 70.00%\n",
      "Epoch 5, Loss: 0.6943, Accuracy: 58.89%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "Accuracy of the model on the test set: 70.00%\n",
      "Epoch 6, Loss: 0.6929, Accuracy: 62.22%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 0], device='cuda:0')\n",
      "Accuracy of the model on the test set: 30.00%\n",
      "Epoch 7, Loss: 0.6829, Accuracy: 60.56%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "Accuracy of the model on the test set: 70.00%\n",
      "Epoch 8, Loss: 0.6852, Accuracy: 61.67%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 0, 0, 0], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 0, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 0, 1], device='cuda:0')\n",
      "Accuracy of the model on the test set: 45.00%\n",
      "Epoch 9, Loss: 0.6890, Accuracy: 62.78%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "Accuracy of the model on the test set: 70.00%\n",
      "Epoch 10, Loss: 0.7365, Accuracy: 52.22%\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 0, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([0, 1, 0, 0], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "tensor([1, 1, 1, 1], device='cuda:0')\n",
      "Accuracy of the model on the test set: 70.00%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = AudioClassifier().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(model, device, train_loader, optimizer, criterion, num_epochs=10):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        for data, targets in train_loader:\n",
    "            data = data.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data)  # Add channel dimension\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute accuracy\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            # print(total)\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        accuracy = 100 * correct / total\n",
    "        print(f'Epoch {epoch+1}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
    "        accuracy = test_model(model, testdataloader, device)\n",
    "\n",
    "train(model, device, traindataloader, optimizer, criterion)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T14:38:15.048564300Z",
     "start_time": "2024-07-31T14:35:46.996449300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
